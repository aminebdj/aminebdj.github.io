---
name: Robust Model poisoning attack to fake clients defense 
tools: [Federated learning, Model poisoning attack]
image: ../images/projects/FL.png
description: 'We explore the attack surface of federated learning (FL) and focus on model-
poisoning attacks using fake clients. We propose a novel attack strategy that
leverages fake clients to evade detection by FLdetector, a detection method that
leverages gradient inconsistency. The effectiveness of the proposed attack is
evaluated by measuring the detection accuracy and its impact on the training
process and resulting model accuracy. The experiments show that the proposed
attack consistently outperforms the baseline prior to detection in terms of test
accuracy, while we also show that the detector identifies good clients as bad clients
with high false positive and false negative rates. Further, we demonstrate the
scalability of the attack and highlight the need for effective countermeasures in
real-world FL scenarios. Overall, our study presents an important contribution to
understanding the vulnerabilities and potential consequences of model poisoning
attacks using fake clients in FL systems.'
external_url: ''
code: 'https://github.com/aminebdj/FCD/tree/master'
paper: 'https://mbzuaiac-my.sharepoint.com/:b:/g/personal/mohamed_boudjoghra_mbzuai_ac_ae/EdeGQvyehh5JjnAec4eJ0lIBXx-g8wnnr36NZVRErNTfRQ?e=bj4oH2'
---